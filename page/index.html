<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>M.T</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>Data Analyst Resume</h1>
    </header>
    <main>
        <section id="about">
            <h2>About Me</h2>
            <p>My name is Matt, my main skills revolve around predictive analysis, data scraping, and data cleaning. <br> I live next to Africa, my timezone is GMT+0</p>
        </section>
        <section id="skills">
            <h2>Skills</h2>
            <ul>
                <li>Data Scraping</li>
                <li>Predictive Analysis</li>
                <li>Machine Learning</li>
                <li>Data Visualization</li>
                <li>Statistical Analysis</li>
            </ul>
        </section>
        <section id="projects">
            <h2>Projects</h2>
            <ul>
                <li>
                    <h3 onclick="toggleProject('project1')">Second-hand Car Price Predictor <span id="toggleIcon-project1">▼</span></h3>
					<p>Built an algorithm that scrapped data from the website <a href="https://www.ooyyo.com/spain" target="_blank">Ooyyo</a>, developed an algorithm to predict the price of a car (mean error of 17%), and conducted a small study to identify trends.</p>
                    <div id="projectContent-project1" style="display: none;">
                        <p><b>This project had 3 phases:</b></p>
						<ul>
							<li> · Scrapping off the data</li>
							<li> · Finding out any trends</li>
							<li> · Building a predictive model with xgboost</li>
						</ul>
						<br>
						<p><b>Scrapping off the data</b><br>
						The scrapped website was composed of a pages with 7 to 9 cars each one. <br>
						The publication of each car on the list did not have the whole information in it, <br>
						so I had to parse through the html code to get the url of the page of each specific car. <br>
						The information of each car was loaded through a javascript, so normal http requests wouldnt work, <br>
						selenium allowed me to load the javascript(python library) and then grab the information. <br>
						<br>
						After processing all the loaded cars, I had to progress to the next page. <br>
						At the bottom of the page there was a button that led you to the next page, this button had an url, I just had to get it and then repeat the process. <br>
						<br>
						After repeating this process a couple of hundred of times, I saved all the information on a csv file using pandas. <br>
						These were the values that would be saved: <br>
						<b>Brand, car_price, price_rating, model, trim, km, fuel_type, body_type, color, power, transmissions</b>
						<iframe src="jupyter_data_scrapper.html" width="100%" height="600px"></iframe>
                    </div>
                </li>
                <!-- Add more project entries as needed -->
            </ul>
        </section>
    </main>
    <footer>
        <p>Hello there.</p>
    </footer>
    <script>
        function toggleProject(projectId) {
            var projectContent = document.getElementById("projectContent-" + projectId);
            var toggleIcon = document.getElementById("toggleIcon-" + projectId);

            if (projectContent.style.display === "none") {
                projectContent.style.display = "block";
                toggleIcon.innerHTML = "▲";
            } else {
                projectContent.style.display = "none";
                toggleIcon.innerHTML = "▼";
            }
        }
    </script>
</body>
</html>
